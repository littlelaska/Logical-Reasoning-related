{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15ad66fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import json\n",
    "import time \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c04bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"llms/Qwen2.5-7B-Instruct/\"\n",
    "# model_path = \"llms/llama3.1-8B-Instruct/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaecf4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from: llms/Qwen2.5-7B-Instruct/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.08s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "print(\"loading model from:\", model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=\"auto\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d65db332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'plz introduce urself'}, {'role': 'user', 'content': 'plz introduce urself'}]\n",
      "<|im_start|>system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "plz introduce urself<|im_end|>\n",
      "<|im_start|>user\n",
      "plz introduce urself<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "messages = [{\"role\":\"user\", \"content\":\"plz introduce urself\"}]\n",
    "print(messages)\n",
    "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "model_input = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "generated_ids = model.generate(**model_input, max_new_tokens=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "947dc841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
      "            553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
      "             13, 151645,    198, 151644,    872,    198,    500,     89,  19131,\n",
      "           4335,    721, 151645,    198, 151644,    872,    198,    500,     89,\n",
      "          19131,   4335,    721, 151645,    198, 151644,  77091,    198,   9707,\n",
      "              0,    358,   2776,   1207,  16948,     11,    264,   3460,   4128,\n",
      "           1614,   3465,    553,  54364,  14817,     13,    358,   2776,   1588,\n",
      "            311,   1492,    498,    448,    894,   4755,    476,   9079,    498,\n",
      "           2578,    614,     11,   3425,    432,    594,    911,   1995,  18615,\n",
      "             11,   3491,  98146,     11,  11521,   4378,     11,    476,   1101,\n",
      "          50967,     13,   2585,    646,    358,   7789,    498,   3351,     30,\n",
      "         151645]], device='cuda:0')\n",
      "tensor([151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
      "           553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
      "            13, 151645,    198, 151644,    872,    198,    500,     89,  19131,\n",
      "          4335,    721, 151645,    198, 151644,    872,    198,    500,     89,\n",
      "         19131,   4335,    721, 151645,    198, 151644,  77091,    198,   9707,\n",
      "             0,    358,   2776,   1207,  16948,     11,    264,   3460,   4128,\n",
      "          1614,   3465,    553,  54364,  14817,     13,    358,   2776,   1588,\n",
      "           311,   1492,    498,    448,    894,   4755,    476,   9079,    498,\n",
      "          2578,    614,     11,   3425,    432,    594,    911,   1995,  18615,\n",
      "            11,   3491,  98146,     11,  11521,   4378,     11,    476,   1101,\n",
      "         50967,     13,   2585,    646,    358,   7789,    498,   3351,     30,\n",
      "        151645], device='cuda:0')\n",
      "<class 'torch.Tensor'> torch.Size([1, 100])\n",
      "1\n",
      "tensor([[151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
      "            553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
      "             13, 151645,    198, 151644,    872,    198,    500,     89,  19131,\n",
      "           4335,    721, 151645,    198, 151644,    872,    198,    500,     89,\n",
      "          19131,   4335,    721, 151645,    198, 151644,  77091,    198]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(generated_ids)\n",
    "print(generated_ids[0])\n",
    "print(type(generated_ids), generated_ids.shape)\n",
    "print(len(model_input.input_ids))\n",
    "print(model_input.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "080bbedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Hello! I'm Qwen, a large language model created by Alibaba Cloud. I'm here to help you with any questions or tasks you might have, whether it's about information lookup, problem-solving, creative writing, or just chatting. How can I assist you today?\"]\n"
     ]
    }
   ],
   "source": [
    "output = tokenizer.batch_decode(generated_ids[:, len(model_input.input_ids[0]):], skip_special_tokens=True)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bab9326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
